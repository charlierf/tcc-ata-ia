# ğŸ“š ReferÃªncias BibliogrÃ¡ficas - Literatura CientÃ­fica

Esta pasta contÃ©m os artigos cientÃ­ficos que fundamentam as decisÃµes tÃ©cnicas do projeto.

## ğŸ—‚ï¸ Estrutura de OrganizaÃ§Ã£o

```plaintext
docs/referencias/
â”œâ”€â”€ asr/                      â† Automatic Speech Recognition
â”‚   â”œâ”€â”€ whisper/             â† Modelo Whisper (OpenAI)
â”‚   â”œâ”€â”€ wav2vec/             â† Wav2Vec2 (Meta/Facebook)
â”‚   â””â”€â”€ general/             â† ASR geral
â”œâ”€â”€ nlp/                     â† Natural Language Processing
â”‚   â”œâ”€â”€ summarization/       â† SumarizaÃ§Ã£o de texto
â”‚   â”œâ”€â”€ ner/                 â† Named Entity Recognition
â”‚   â””â”€â”€ llm/                 â† Large Language Models
â”œâ”€â”€ evaluation/              â† MÃ©tricas e avaliaÃ§Ã£o
â””â”€â”€ related-work/            â† Trabalhos relacionados
```

## ğŸ“– Artigos Principais

### ğŸ™ï¸ **Automatic Speech Recognition (ASR)**

#### Whisper - OpenAI (2022)
- **Artigo:** "Robust Speech Recognition via Large-Scale Weak Supervision"
- **Autores:** Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, Ilya Sutskever
- **RelevÃ¢ncia:** Modelo base para transcriÃ§Ã£o, justifica configuraÃ§Ã£o 16kHz
- **Status:** ğŸ” **BUSCAR** - Fundamental para o projeto

#### Wav2Vec2 - Meta (2020)
- **Artigo:** "wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations"
- **Autores:** Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, Michael Auli
- **RelevÃ¢ncia:** ComparaÃ§Ã£o com Whisper, fundamentaÃ§Ã£o teÃ³rica ASR
- **Status:** ğŸ” **BUSCAR** - Importante para comparaÃ§Ãµes

### ğŸ¤– **Natural Language Processing**

#### BART - Facebook (2019)
- **Artigo:** "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"
- **Autores:** Mike Lewis, Yinhan Liu, Naman Goyal, et al.
- **RelevÃ¢ncia:** Modelo de sumarizaÃ§Ã£o, base para DistilBART
- **Status:** ğŸ” **BUSCAR** - Para mÃ³dulo de sumarizaÃ§Ã£o

#### T5 - Google (2019)
- **Artigo:** "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"
- **Autores:** Colin Raffel, Noam Shazeer, Adam Roberts, et al.
- **RelevÃ¢ncia:** Alternativa para sumarizaÃ§Ã£o e geraÃ§Ã£o de texto
- **Status:** ğŸ” **BUSCAR** - ComparaÃ§Ã£o de modelos

### ğŸ·ï¸ **Named Entity Recognition**

#### SpaCy Portuguese Models
- **DocumentaÃ§Ã£o:** Models and datasets for Portuguese NER
- **RelevÃ¢ncia:** IdentificaÃ§Ã£o de participantes, locais, datas nas atas
- **Status:** ğŸ” **BUSCAR** - DocumentaÃ§Ã£o tÃ©cnica

#### BERT for Portuguese
- **Artigo:** "BERTimbau: Portuguese BERT for Brazilian Portuguese"
- **Autores:** FÃ¡bio Souza, Rodrigo Nogueira, Roberto Lotufo
- **RelevÃ¢ncia:** Modelo especÃ­fico para portuguÃªs brasileiro
- **Status:** ğŸ” **BUSCAR** - Importante para NER em portuguÃªs

### ğŸ“Š **Evaluation Metrics**

#### ROUGE for Summarization
- **Artigo:** "ROUGE: A Package for Automatic Evaluation of Summaries"
- **Autor:** Chin-Yew Lin
- **RelevÃ¢ncia:** MÃ©trica padrÃ£o para avaliaÃ§Ã£o de sumarizaÃ§Ã£o
- **Status:** ğŸ” **BUSCAR** - Essencial para avaliaÃ§Ã£o

#### WER for ASR
- **DocumentaÃ§Ã£o:** Word Error Rate calculation and significance
- **RelevÃ¢ncia:** MÃ©trica padrÃ£o para avaliaÃ§Ã£o de transcriÃ§Ã£o
- **Status:** ğŸ” **BUSCAR** - DocumentaÃ§Ã£o tÃ©cnica

## ğŸ¯ **Prioridade de Busca**

### â­ **Alta Prioridade** (Fundamentais)
1. **Whisper (Radford et al., 2022)** - Base do projeto
2. **ROUGE (Lin, 2004)** - AvaliaÃ§Ã£o de sumarizaÃ§Ã£o
3. **BERTimbau (Souza et al., 2020)** - NLP em portuguÃªs

### ğŸ”¥ **MÃ©dia Prioridade** (Importantes)
4. **Wav2Vec2 (Baevski et al., 2020)** - ComparaÃ§Ã£o ASR
5. **BART (Lewis et al., 2019)** - SumarizaÃ§Ã£o
6. **T5 (Raffel et al., 2019)** - Alternativa de sumarizaÃ§Ã£o

### ğŸ“š **Baixa Prioridade** (Complementares)
7. Trabalhos relacionados sobre atas automÃ¡ticas
8. Estudos de caso institucionais
9. MÃ©tricas especÃ­ficas de domÃ­nio

## ğŸ” **Onde Buscar**

### Bases de Dados AcadÃªmicas
- **arXiv.org** - PrÃ©-prints (acesso livre)
- **Google Scholar** - Busca ampla
- **IEEE Xplore** - ConferÃªncias tÃ©cnicas
- **ACL Anthology** - NLP especÃ­fico
- **Portal CAPES** - Via UFS (acesso institucional)

### RepositÃ³rios EspecÃ­ficos
- **Papers With Code** - Artigos com implementaÃ§Ãµes
- **Hugging Face Papers** - Modelos e documentaÃ§Ã£o
- **OpenAI Research** - Artigos da OpenAI
- **Meta Research** - Artigos da Meta/Facebook

## ğŸ“ **Como Usar**

1. **Baixar PDFs** e salvar nas subpastas apropriadas
2. **Nomear arquivos:** `autor_ano_titulo-curto.pdf`
3. **Criar resumos:** Para cada artigo, criar um `.md` com resumo
4. **Citar no TCC:** Usar referÃªncias completas na monografia

### Exemplo de Estrutura:
```
docs/referencias/asr/whisper/
â”œâ”€â”€ radford_2022_robust-speech-recognition.pdf
â”œâ”€â”€ radford_2022_resumo.md
â””â”€â”€ whisper_technical_specs.md
```

## ğŸ“ **ImportÃ¢ncia para o TCC**

### **Credibilidade CientÃ­fica**
- Fundamenta escolhas tÃ©cnicas com literatura peer-reviewed
- Demonstra conhecimento do estado da arte
- Permite comparaÃ§Ãµes metodolÃ³gicas vÃ¡lidas

### **Metodologia Robusta**
- Justifica configuraÃ§Ãµes especÃ­ficas (16kHz, mono, WAV)
- Embasa mÃ©tricas de avaliaÃ§Ã£o (ROUGE, WER)
- Suporta decisÃµes arquiteturais

### **ContribuiÃ§Ã£o Original**
- Identifica gaps na literatura
- Posiciona o trabalho no contexto cientÃ­fico
- Facilita discussÃ£o de resultados

---

**PrÃ³ximos passos:**
1. Buscar artigos marcados como "BUSCAR"
2. Criar resumos executivos
3. Integrar citaÃ§Ãµes no texto do TCC
4. Manter bibliografia atualizada
