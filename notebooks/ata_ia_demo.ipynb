{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8397a809",
      "metadata": {
        "id": "8397a809"
      },
      "source": [
        "# üéØ Sistema de Gera√ß√£o Autom√°tica de Atas - UFS\n",
        "\n",
        "**Demonstra√ß√£o Interativa para Conselho Universit√°rio**\n",
        "\n",
        "Este notebook implementa uma interface visual para demonstrar o sistema de gera√ß√£o autom√°tica de atas de reuni√£o desenvolvido para a Universidade Federal de Sergipe (UFS).\n",
        "\n",
        "## üöÄ Funcionalidades\n",
        "\n",
        "- ‚úÖ **Upload de √°udio** - Suporte a .mp3, .wav, .m4a\n",
        "- ‚úÖ **Diariza√ß√£o autom√°tica** - Separa√ß√£o de speakers com IA\n",
        "- ‚úÖ **Transcri√ß√£o precisa** - Convers√£o √°udio ‚Üí texto com Whisper\n",
        "- ‚úÖ **Gera√ß√£o de ata** - Cria√ß√£o autom√°tica de ata estruturada\n",
        "- ‚úÖ **Interface amig√°vel** - Demonstra√ß√£o visual completa\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f42c97b",
      "metadata": {
        "id": "3f42c97b"
      },
      "source": [
        "## üì¶ Instala√ß√£o das Depend√™ncias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a995a204",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a995a204",
        "outputId": "69764c19-0040-4366-f2cc-043386a06062"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Instala√ß√£o das depend√™ncias necess√°rias\n",
        "!pip install gradio -q\n",
        "!pip install git+https://github.com/openai/whisper.git -q\n",
        "!pip install openai -q\n",
        "!pip install pyannote.audio -q\n",
        "!pip install torch torchvision torchaudio -q\n",
        "!pip install pydub -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "5a52d80c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a52d80c",
        "outputId": "21da2e56-b18f-40d1-8e86-0036e1f4b5ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Bibliotecas importadas com sucesso!\n"
          ]
        }
      ],
      "source": [
        "# Imports necess√°rios\n",
        "import gradio as gr\n",
        "import whisper\n",
        "import os\n",
        "from openai import OpenAI\n",
        "from pyannote.audio import Pipeline\n",
        "import torch\n",
        "from datetime import datetime\n",
        "import json\n",
        "import tempfile\n",
        "from collections import defaultdict\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ Bibliotecas importadas com sucesso!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34bd55f2",
      "metadata": {
        "id": "34bd55f2"
      },
      "source": [
        "## ‚öôÔ∏è Configura√ß√£o dos Modelos de IA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "fee5153b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fee5153b",
        "outputId": "0efc85bb-7abe-401d-f97b-538509e42c69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Cliente OpenAI configurado!\n"
          ]
        }
      ],
      "source": [
        "# Configura√ß√£o da API OpenAI\n",
        "# IMPORTANTE: Substitua pela sua chave de API\n",
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")  # ou use os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "if OPENAI_API_KEY == \"your-openai-api-key-here\":\n",
        "    print(\"‚ö†Ô∏è ATEN√á√ÉO: Configure sua chave da OpenAI API\")\n",
        "    print(\"   Edite a vari√°vel OPENAI_API_KEY acima\")\n",
        "else:\n",
        "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "    print(\"‚úÖ Cliente OpenAI configurado!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "41d10423",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41d10423",
        "outputId": "2f6bfd58-8503-4174-c7ef-019321d2dbb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Carregando modelo Whisper...\n",
            "‚úÖ Whisper carregado!\n",
            "üîÑ Configurando pipeline de diariza√ß√£o...\n",
            "   Dispositivo: cuda\n",
            "\n",
            "Could not download 'pyannote/speaker-diarization' pipeline.\n",
            "It might be because the pipeline is private or gated so make\n",
            "sure to authenticate. Visit https://hf.co/settings/tokens to\n",
            "create your access token and retry with:\n",
            "\n",
            "   >>> Pipeline.from_pretrained('pyannote/speaker-diarization',\n",
            "   ...                          use_auth_token=YOUR_AUTH_TOKEN)\n",
            "\n",
            "If this still does not work, it might be because the pipeline is gated:\n",
            "visit https://hf.co/pyannote/speaker-diarization to accept the user conditions.\n",
            "‚ö†Ô∏è Diariza√ß√£o n√£o dispon√≠vel: 'NoneType' object has no attribute 'to'\n",
            "   Sistema funcionar√° sem separa√ß√£o de speakers\n"
          ]
        }
      ],
      "source": [
        "# Carregamento dos modelos\n",
        "print(\"üîÑ Carregando modelo Whisper...\")\n",
        "whisper_model = whisper.load_model(\"small\")\n",
        "print(\"‚úÖ Whisper carregado!\")\n",
        "\n",
        "print(\"üîÑ Configurando pipeline de diariza√ß√£o...\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"   Dispositivo: {device}\")\n",
        "\n",
        "# Nota: Para usar pyannote, aceite os termos em:\n",
        "# https://huggingface.co/pyannote/speaker-diarization\n",
        "# https://huggingface.co/pyannote/segmentation\n",
        "token = userdata.get(\"HF_TOKEN\")\n",
        "try:\n",
        "    diarization_pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization@2.1\", use_auth_token=token)\n",
        "    diarization_pipeline.to(device)\n",
        "    print(\"‚úÖ Pipeline de diariza√ß√£o configurado!\")\n",
        "    DIARIZATION_AVAILABLE = True\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Diariza√ß√£o n√£o dispon√≠vel: {e}\")\n",
        "    print(\"   Sistema funcionar√° sem separa√ß√£o de speakers\")\n",
        "    DIARIZATION_AVAILABLE = False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "292e530a",
      "metadata": {
        "id": "292e530a"
      },
      "source": [
        "## üõ†Ô∏è Fun√ß√µes do Sistema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "0a4ce5c7",
      "metadata": {
        "id": "0a4ce5c7"
      },
      "outputs": [],
      "source": [
        "def perform_diarization(audio_path):\n",
        "    \"\"\"\n",
        "    Realiza diariza√ß√£o (separa√ß√£o de speakers) do √°udio\n",
        "    \"\"\"\n",
        "    if not DIARIZATION_AVAILABLE:\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        diarization = diarization_pipeline(audio_path)\n",
        "        speakers_info = []\n",
        "\n",
        "        for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
        "            speakers_info.append({\n",
        "                \"speaker\": speaker,\n",
        "                \"start\": turn.start,\n",
        "                \"end\": turn.end,\n",
        "                \"duration\": turn.end - turn.start\n",
        "            })\n",
        "\n",
        "        return speakers_info\n",
        "    except Exception as e:\n",
        "        print(f\"Erro na diariza√ß√£o: {e}\")\n",
        "        return []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "9a83af9a",
      "metadata": {
        "id": "9a83af9a"
      },
      "outputs": [],
      "source": [
        "def transcribe_with_diarization(audio_path, speakers_info):\n",
        "    \"\"\"\n",
        "    Transcreve √°udio com informa√ß√µes de diariza√ß√£o\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Transcri√ß√£o completa com Whisper\n",
        "        result = whisper_model.transcribe(audio_path, language=\"pt\")\n",
        "        full_transcription = result[\"text\"]\n",
        "        segments = result.get(\"segments\", [])\n",
        "\n",
        "        if not speakers_info or not segments:\n",
        "            return [], full_transcription\n",
        "\n",
        "        # Associar segmentos com speakers\n",
        "        speaker_transcriptions = []\n",
        "\n",
        "        for segment in segments:\n",
        "            segment_center = (segment[\"start\"] + segment[\"end\"]) / 2\n",
        "            assigned_speaker = \"PARTICIPANTE\"\n",
        "\n",
        "            # Encontrar speaker para este segmento\n",
        "            for speaker_info in speakers_info:\n",
        "                if speaker_info[\"start\"] <= segment_center <= speaker_info[\"end\"]:\n",
        "                    assigned_speaker = speaker_info[\"speaker\"]\n",
        "                    break\n",
        "\n",
        "            speaker_transcriptions.append({\n",
        "                \"speaker\": assigned_speaker,\n",
        "                \"start\": segment[\"start\"],\n",
        "                \"end\": segment[\"end\"],\n",
        "                \"text\": segment[\"text\"].strip(),\n",
        "                \"duration\": segment[\"end\"] - segment[\"start\"]\n",
        "            })\n",
        "\n",
        "        return speaker_transcriptions, full_transcription\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro na transcri√ß√£o: {e}\")\n",
        "        return [], \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "f846972f",
      "metadata": {
        "id": "f846972f"
      },
      "outputs": [],
      "source": [
        "def generate_speaker_stats(speaker_transcriptions):\n",
        "    \"\"\"\n",
        "    Gera estat√≠sticas dos participantes\n",
        "    \"\"\"\n",
        "    speaker_stats = defaultdict(lambda: {\"total_time\": 0, \"segments\": 0, \"words\": 0})\n",
        "\n",
        "    for segment in speaker_transcriptions:\n",
        "        speaker = segment[\"speaker\"]\n",
        "        speaker_stats[speaker][\"total_time\"] += segment[\"duration\"]\n",
        "        speaker_stats[speaker][\"segments\"] += 1\n",
        "        speaker_stats[speaker][\"words\"] += len(segment[\"text\"].split())\n",
        "\n",
        "    return dict(speaker_stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "26dc662e",
      "metadata": {
        "id": "26dc662e"
      },
      "outputs": [],
      "source": [
        "def generate_meeting_minutes(transcription, speaker_stats=None):\n",
        "    \"\"\"\n",
        "    Gera ata de reuni√£o usando OpenAI\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Preparar contexto dos participantes\n",
        "        speaker_context = \"\"\n",
        "        if speaker_stats:\n",
        "            speaker_context = \"\\n\\n=== PARTICIPANTES IDENTIFICADOS ===\\n\"\n",
        "            for speaker, stats in speaker_stats.items():\n",
        "                speaker_context += f\"- {speaker}: {stats['total_time']:.1f}s de fala, {stats['segments']} interven√ß√µes\\n\"\n",
        "\n",
        "        system_prompt = \"\"\"Voc√™ √© um assistente especializado em gerar atas de reuni√£o para o contexto universit√°rio brasileiro.\n",
        "\n",
        "        Sua tarefa √© analisar a transcri√ß√£o de uma reuni√£o e criar uma ata formal e estruturada seguindo os padr√µes acad√™micos.\n",
        "\n",
        "        A ata deve conter:\n",
        "        1. CABE√áALHO - Data, participantes, tipo de reuni√£o\n",
        "        2. PAUTA - Principais t√≥picos discutidos\n",
        "        3. DELIBERA√á√ïES - Decis√µes tomadas e vota√ß√µes\n",
        "        4. ENCAMINHAMENTOS - A√ß√µes futuras e respons√°veis\n",
        "        5. OBSERVA√á√ïES - Informa√ß√µes adicionais relevantes\n",
        "\n",
        "        Use linguagem formal, objetiva e organize as informa√ß√µes de forma clara e hier√°rquica.\n",
        "        Identifique decis√µes importantes, pontos de consenso e discord√¢ncia quando aplic√°vel.\"\"\"\n",
        "\n",
        "        user_prompt = f\"\"\"TRANSCRI√á√ÉO DA REUNI√ÉO:\n",
        "        {transcription}\n",
        "        {speaker_context}\n",
        "\n",
        "        Por favor, gere uma ata completa, formal e bem estruturada baseada nesta transcri√ß√£o.\n",
        "        Organize as informa√ß√µes de forma profissional adequada para o ambiente universit√°rio.\"\"\"\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_prompt}\n",
        "            ],\n",
        "            temperature=0.2,\n",
        "            max_tokens=3000\n",
        "        )\n",
        "\n",
        "        return response.choices[0].message.content\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Erro na gera√ß√£o da ata: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "7816bc34",
      "metadata": {
        "id": "7816bc34"
      },
      "outputs": [],
      "source": [
        "def process_audio_file(audio_file, progress=gr.Progress()):\n",
        "    \"\"\"\n",
        "    Fun√ß√£o principal que processa o arquivo de √°udio\n",
        "    \"\"\"\n",
        "    if audio_file is None:\n",
        "        yield \"‚ùå Nenhum arquivo de √°udio foi enviado.\", \"\", \"\", \"\", \"Aguardando upload...\", \"0s\"\n",
        "        return\n",
        "\n",
        "    start_time = time.time()\n",
        "    def update_status(message, prog):\n",
        "        elapsed = time.time() - start_time\n",
        "        yield \"\", \"\", \"\", \"\", message, f\"{elapsed:.1f}s\"\n",
        "        progress(prog, desc=message)\n",
        "\n",
        "\n",
        "    try:\n",
        "        yield from update_status(\"üéµ Carregando arquivo de √°udio...\", 0)\n",
        "\n",
        "        # Etapa 1: Diariza√ß√£o\n",
        "        yield from update_status(\"üé≠ Identificando participantes (diariza√ß√£o)... Pode levar alguns minutos...\", 0.1)\n",
        "        speakers_info = perform_diarization(audio_file)\n",
        "\n",
        "        num_speakers = len(set([s['speaker'] for s in speakers_info])) if speakers_info else 1\n",
        "\n",
        "        # Etapa 2: Transcri√ß√£o\n",
        "        yield from update_status(\"üé§ Transcrevendo √°udio com Whisper...\", 0.4)\n",
        "        speaker_transcriptions, full_transcription = transcribe_with_diarization(audio_file, speakers_info)\n",
        "\n",
        "        if not full_transcription:\n",
        "            yield \"‚ùå Erro na transcri√ß√£o do √°udio.\", \"\", \"\", \"\", \"Erro na transcri√ß√£o\", f\"{time.time() - start_time:.1f}s\"\n",
        "            return\n",
        "\n",
        "        # Etapa 3: Estat√≠sticas\n",
        "        yield from update_status(\"üìä Calculando estat√≠sticas dos participantes...\", 0.6)\n",
        "        speaker_stats = generate_speaker_stats(speaker_transcriptions)\n",
        "\n",
        "        # Etapa 4: Gera√ß√£o da ata\n",
        "        yield from update_status(\"üìù Gerando ata de reuni√£o com OpenAI GPT...\", 0.8)\n",
        "        meeting_minutes = generate_meeting_minutes(full_transcription, speaker_stats)\n",
        "\n",
        "        yield from update_status(\"‚úÖ Processamento conclu√≠do!\", 1.0)\n",
        "\n",
        "        # Formata√ß√£o dos resultados\n",
        "        stats_text = f\"\"\"## üìä Estat√≠sticas da Reuni√£o\n",
        "\n",
        "**Participantes identificados:** {num_speakers}\n",
        "**Dura√ß√£o da transcri√ß√£o:** {len(full_transcription)} caracteres\n",
        "**Processado em:** {datetime.now().strftime('%d/%m/%Y √†s %H:%M:%S')}\n",
        "\n",
        "### Participa√ß√£o por Speaker:\n",
        "\"\"\"\n",
        "\n",
        "        if speaker_stats:\n",
        "            for speaker, stats in sorted(speaker_stats.items()):\n",
        "                stats_text += f\"\\n- **{speaker}**: {stats['total_time']:.1f}s ({stats['segments']} interven√ß√µes, {stats['words']} palavras)\"\n",
        "        else:\n",
        "            stats_text += \"\\n- N√£o foi poss√≠vel separar por participantes\"\n",
        "\n",
        "        # Transcri√ß√£o formatada\n",
        "        transcription_display = f\"\"\"## üé§ Transcri√ß√£o Completa\n",
        "\n",
        "{full_transcription[:2000]}{'...' if len(full_transcription) > 2000 else ''}\n",
        "\"\"\"\n",
        "\n",
        "        # Ata formatada\n",
        "        ata_display = f\"\"\"## üìã Ata de Reuni√£o Gerada\n",
        "\n",
        "{meeting_minutes}\n",
        "\"\"\"\n",
        "\n",
        "        success_msg = f\"\"\"‚úÖ **Processamento conclu√≠do com sucesso!**\n",
        "\n",
        "üéØ **Arquivo processado:** {os.path.basename(audio_file)}\n",
        "üïí **Hor√°rio:** {datetime.now().strftime('%d/%m/%Y √†s %H:%M:%S')}\n",
        "üë• **Participantes:** {num_speakers} identificados\n",
        "üìÑ **Transcri√ß√£o:** {len(full_transcription)} caracteres\n",
        "\"\"\"\n",
        "        elapsed = time.time() - start_time\n",
        "        yield success_msg, stats_text, transcription_display, ata_display, \"Processamento conclu√≠do!\", f\"{elapsed:.1f}s\"\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"‚ùå **Erro no processamento:** {type(e).__name__}: {str(e)}\"\n",
        "        elapsed = time.time() - start_time\n",
        "        yield error_msg, \"\", \"\", \"\", \"Erro no processamento\", f\"{elapsed:.1f}s\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e1cdc8f",
      "metadata": {
        "id": "1e1cdc8f"
      },
      "source": [
        "## üé® Interface Gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "6ffc3913",
      "metadata": {
        "id": "6ffc3913"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def create_interface():\n",
        "    \"\"\"\n",
        "    Cria a interface Gradio com feedback visual\n",
        "    \"\"\"\n",
        "\n",
        "    # CSS personalizado\n",
        "    css = \"\"\"\n",
        "    .gradio-container {\n",
        "        max-width: 1200px !important;\n",
        "    }\n",
        "    .header {\n",
        "        text-align: center;\n",
        "        background: linear-gradient(90deg, #1f4e79, #2e7d32);\n",
        "        color: white;\n",
        "        padding: 20px;\n",
        "        border-radius: 10px;\n",
        "        margin-bottom: 20px;\n",
        "    }\n",
        "    .status-success {\n",
        "        background-color: #e8f5e8;\n",
        "        border: 1px solid #4caf50;\n",
        "        border-radius: 5px;\n",
        "        padding: 10px;\n",
        "    }\n",
        "    .status-error {\n",
        "        background-color: #ffebee;\n",
        "        border: 1px solid #f44336;\n",
        "        border-radius: 5px;\n",
        "        padding: 10px;\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    with gr.Blocks(css=css, title=\"Sistema de Atas UFS\") as interface:\n",
        "\n",
        "        # Cabe√ßalho\n",
        "        gr.HTML(\"\"\"\n",
        "        <div class=\"header\">\n",
        "            <h1>Sistema de Gera√ß√£o Autom√°tica de Atas</h1>\n",
        "            <h2>Universidade Federal de Sergipe - UFS</h2>\n",
        "            <p><strong>Demonstra√ß√£o</strong></p>\n",
        "        </div>\n",
        "        \"\"\")\n",
        "\n",
        "        gr.Markdown(\"\"\"\n",
        "        ### üìã Como usar:\n",
        "        1. **Fa√ßa upload** de um arquivo de √°udio (.mp3, .wav, .m4a)\n",
        "        2. **Clique em \"Processar √Åudio\"** e aguarde. Uma barra de progresso ser√° exibida.\n",
        "        3. **Visualize os resultados** nas abas abaixo\n",
        "\n",
        "        > O processamento pode levar alguns minutos dependendo do tamanho do arquivo\n",
        "        \"\"\")\n",
        "\n",
        "        # Input de √°udio\n",
        "        with gr.Row():\n",
        "            audio_input = gr.Audio(\n",
        "                label=\"üìÅ Upload do Arquivo de √Åudio\",\n",
        "                type=\"filepath\",\n",
        "                format=\"wav\" # Sugere WAV, mas aceita outros formatos compat√≠veis com pydub\n",
        "            )\n",
        "\n",
        "        # √Årea de feedback\n",
        "        with gr.Row():\n",
        "            status_text = gr.Textbox(label=\"Status do Processamento\", interactive=False, lines=1)\n",
        "\n",
        "        # Bot√£o de processamento\n",
        "        process_btn = gr.Button(\n",
        "            \"üöÄ Processar √Åudio\",\n",
        "            variant=\"primary\",\n",
        "            size=\"lg\"\n",
        "        )\n",
        "\n",
        "        # Outputs organizados em abas\n",
        "        with gr.Tabs():\n",
        "\n",
        "            with gr.TabItem(\"üìä Status & Estat√≠sticas\"):\n",
        "                summary_output = gr.Markdown(label=\"Resumo do Processamento\")\n",
        "                stats_output = gr.Markdown(label=\"Estat√≠sticas Detalhadas\")\n",
        "\n",
        "            with gr.TabItem(\"üé§ Transcri√ß√£o\"):\n",
        "                transcription_output = gr.Markdown(label=\"Transcri√ß√£o Completa\")\n",
        "\n",
        "            with gr.TabItem(\"üìã Ata Gerada\"):\n",
        "                ata_output = gr.Markdown(label=\"Ata de Reuni√£o\")\n",
        "\n",
        "\n",
        "        # Conectar o bot√£o com a fun√ß√£o\n",
        "        process_btn.click(\n",
        "            fn=process_audio_file,\n",
        "            inputs=[audio_input],\n",
        "            outputs=[summary_output, stats_output, transcription_output, ata_output, status_text],\n",
        "            show_progress=True # Ativa a barra de progresso nativa do Gradio\n",
        "        )\n",
        "\n",
        "\n",
        "        # Rodap√©\n",
        "        gr.HTML(\"\"\"\n",
        "        <div style=\"text-align: center; margin-top: 30px; padding: 20px; background-color: #000000; color: white; border-radius: 10px;\">\n",
        "            <p><strong>üéì Sistema desenvolvido para a UFS</strong></p>\n",
        "            <p>Tecnologias: Whisper AI + PyAnnote + OpenAI GPT + Gradio</p>\n",
        "            <p><em>Demonstra√ß√£o t√©cnica - TCC Ci√™ncia da Computa√ß√£o</em></p>\n",
        "        </div>\n",
        "        \"\"\")\n",
        "\n",
        "    return interface"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "084faf1d",
      "metadata": {
        "id": "084faf1d"
      },
      "source": [
        "## üöÄ Executar a Aplica√ß√£o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "9e8857b9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e8857b9",
        "outputId": "f10f076b-c9cd-411f-a258-708cc1eaa2b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Whisper: Configurado\n",
            "‚úÖ OpenAI: Configurado\n",
            "‚ö†Ô∏è Diariza√ß√£o: N√£o dispon√≠vel (sistema funcionar√° sem separa√ß√£o de speakers)\n"
          ]
        }
      ],
      "source": [
        "# Verificar se tudo est√° configurado\n",
        "def check_setup():\n",
        "    status = []\n",
        "\n",
        "    # Verificar Whisper\n",
        "    if 'whisper_model' in globals():\n",
        "        status.append(\"‚úÖ Whisper: Configurado\")\n",
        "    else:\n",
        "        status.append(\"‚ùå Whisper: N√£o configurado\")\n",
        "\n",
        "    # Verificar OpenAI\n",
        "    if 'client' in globals():\n",
        "        status.append(\"‚úÖ OpenAI: Configurado\")\n",
        "    else:\n",
        "        status.append(\"‚ùå OpenAI: N√£o configurado\")\n",
        "\n",
        "    # Verificar Diariza√ß√£o\n",
        "    if DIARIZATION_AVAILABLE:\n",
        "        status.append(\"‚úÖ Diariza√ß√£o: Dispon√≠vel\")\n",
        "    else:\n",
        "        status.append(\"‚ö†Ô∏è Diariza√ß√£o: N√£o dispon√≠vel (sistema funcionar√° sem separa√ß√£o de speakers)\")\n",
        "\n",
        "    print(\"\\n\".join(status))\n",
        "    return all(\"‚úÖ\" in s or \"‚ö†Ô∏è\" in s for s in status)\n",
        "\n",
        "setup_ok = check_setup()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd396882",
      "metadata": {
        "id": "dd396882"
      },
      "outputs": [],
      "source": [
        "# Executar a interface\n",
        "if setup_ok:\n",
        "    print(\"üéØ Iniciando Sistema de Gera√ß√£o de Atas - UFS\")\n",
        "    print(\"üì± A interface ser√° aberta em uma nova aba/janela\")\n",
        "    print(\"üîó Ou acesse o link que ser√° exibido abaixo\")\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "    # Criar e executar a interface\n",
        "    demo = create_interface()\n",
        "    demo.launch(\n",
        "        server_name=\"0.0.0.0\",  # Permite acesso externo\n",
        "        # server_port=7860,       # Porta padr√£o do Gradio - Removido para encontrar porta livre automaticamente\n",
        "        share=True,             # Criar link p√∫blico tempor√°rio\n",
        "        debug=True,            # Modo\n",
        "        show_error=True         # Mostrar erros na interface\n",
        "    )\n",
        "else:\n",
        "    print(\"‚ùå Sistema n√£o est√° completamente configurado.\")\n",
        "    print(\"   Verifique as configura√ß√µes acima antes de executar.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb13a682",
      "metadata": {
        "id": "bb13a682"
      },
      "source": [
        "## üìù Instru√ß√µes de Uso para Demonstra√ß√£o\n",
        "\n",
        "### Para o Representante da UFS:\n",
        "\n",
        "1. **Execute todas as c√©lulas acima** na ordem apresentada\n",
        "2. **Configure sua chave da OpenAI** na c√©lula de configura√ß√£o\n",
        "3. **Execute a √∫ltima c√©lula** para abrir a interface\n",
        "4. **Acesse o link** que ser√° gerado (p√∫blico tempor√°rio)\n",
        "\n",
        "### Recursos da Interface:\n",
        "\n",
        "- ‚úÖ **Upload simples** - Arraste e solte arquivos de √°udio\n",
        "- ‚úÖ **Processamento visual** - Barra de progresso em tempo real\n",
        "- ‚úÖ **Resultados organizados** - Abas para cada tipo de informa√ß√£o\n",
        "- ‚úÖ **Estat√≠sticas detalhadas** - Tempo de fala por participante\n",
        "- ‚úÖ **Ata profissional** - Formata√ß√£o adequada para uso oficial\n",
        "\n",
        "### Formatos de √Åudio Suportados:\n",
        "- `.mp3` - Mais comum\n",
        "- `.wav` - Melhor qualidade\n",
        "- `.m4a` - iOS/iPhone\n",
        "\n",
        "---\n",
        "\n",
        "**üéØ Esta √© uma demonstra√ß√£o t√©cnica do sistema proposto para automatiza√ß√£o das atas de reuni√£o do Conselho Universit√°rio da UFS.**"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}