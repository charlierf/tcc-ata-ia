{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b60a5c99",
   "metadata": {},
   "source": [
    "# Prova de Conceito: Transcrição, NER e Geração de Ata\n",
    "Este notebook realiza uma prova de conceito simples para transcrição de áudio, identificação de entidades nomeadas (NER) e geração de ata. Utilizaremos um arquivo de áudio de uma entrevista do Prof. Hendrik como exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfa76a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai-whisper in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (20250625)\n",
      "Requirement already satisfied: transformers in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (4.46.3)\n",
      "Requirement already satisfied: bert-extractive-summarizer in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: protobuf in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (5.29.5)\n",
      "Requirement already satisfied: sentencepiece in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: tqdm in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: more-itertools in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from openai-whisper) (10.5.0)\n",
      "Requirement already satisfied: numba in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from openai-whisper) (0.58.1)\n",
      "Requirement already satisfied: numpy in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from openai-whisper) (1.24.4)\n",
      "Requirement already satisfied: tiktoken in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from openai-whisper) (0.7.0)\n",
      "Requirement already satisfied: torch in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from openai-whisper) (2.4.1)\n",
      "Requirement already satisfied: filelock in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from transformers) (0.34.3)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: scikit-learn in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from bert-extractive-summarizer) (1.3.2)\n",
      "Requirement already satisfied: spacy in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from bert-extractive-summarizer) (3.7.5)\n",
      "Requirement already satisfied: colorama in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.13.2)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from numba->openai-whisper) (0.41.1)\n",
      "Requirement already satisfied: importlib-metadata in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from numba->openai-whisper) (8.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from requests->transformers) (2025.7.14)\n",
      "Requirement already satisfied: scipy>=1.5.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from scikit-learn->bert-extractive-summarizer) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from scikit-learn->bert-extractive-summarizer) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from scikit-learn->bert-extractive-summarizer) (3.5.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from spacy->bert-extractive-summarizer) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from spacy->bert-extractive-summarizer) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from spacy->bert-extractive-summarizer) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from spacy->bert-extractive-summarizer) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from spacy->bert-extractive-summarizer) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from spacy->bert-extractive-summarizer) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from spacy->bert-extractive-summarizer) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from spacy->bert-extractive-summarizer) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from spacy->bert-extractive-summarizer) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from spacy->bert-extractive-summarizer) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from spacy->bert-extractive-summarizer) (0.16.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from spacy->bert-extractive-summarizer) (2.10.6)\n",
      "Requirement already satisfied: jinja2 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from spacy->bert-extractive-summarizer) (3.1.6)\n",
      "Requirement already satisfied: setuptools in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from spacy->bert-extractive-summarizer) (56.0.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from spacy->bert-extractive-summarizer) (3.4.1)\n",
      "Requirement already satisfied: sympy in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from torch->openai-whisper) (1.13.3)\n",
      "Requirement already satisfied: networkx in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from torch->openai-whisper) (3.1)\n",
      "Requirement already satisfied: language-data>=1.2 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy->bert-extractive-summarizer) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->bert-extractive-summarizer) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->bert-extractive-summarizer) (2.27.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy->bert-extractive-summarizer) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy->bert-extractive-summarizer) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy->bert-extractive-summarizer) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy->bert-extractive-summarizer) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy->bert-extractive-summarizer) (14.1.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy->bert-extractive-summarizer) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy->bert-extractive-summarizer) (7.3.0.post1)\n",
      "Requirement already satisfied: zipp>=3.20 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from importlib-metadata->numba->openai-whisper) (3.20.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from jinja2->spacy->bert-extractive-summarizer) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->bert-extractive-summarizer) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->bert-extractive-summarizer) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->bert-extractive-summarizer) (2.19.2)\n",
      "Requirement already satisfied: wrapt in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->bert-extractive-summarizer) (1.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->bert-extractive-summarizer) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "# Instalar as dependências necessárias\n",
    "!pip install openai-whisper transformers bert-extractive-summarizer protobuf sentencepiece tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "683554f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GitHub Projects\\tcc-ata-ia\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuração inicial concluída.\n"
     ]
    }
   ],
   "source": [
    "# Configuração do ambiente\n",
    "# Importação das bibliotecas necessárias\n",
    "import os\n",
    "from pathlib import Path\n",
    "import whisper\n",
    "from transformers import pipeline\n",
    "from summarizer import Summarizer\n",
    "\n",
    "# Verificar se os modelos necessários estão instalados\n",
    "print(\"Configuração inicial concluída.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda74880",
   "metadata": {},
   "source": [
    "## Carregamento do Áudio\n",
    "Carregamos o arquivo de áudio da entrevista para realizar a transcrição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "688fa42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo carregado: ..\\data\\raw\\audio\\entrevista_ufs_fm.mp3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "audio_path = Path(\"../data/raw/audio/entrevista_ufs_fm.mp3\")\n",
    "\n",
    "# Verificar se o arquivo existe\n",
    "if not audio_path.exists():\n",
    "    raise FileNotFoundError(f\"Arquivo de áudio não encontrado: {audio_path}\")\n",
    "\n",
    "print(f\"Arquivo carregado: {audio_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83da1979",
   "metadata": {},
   "source": [
    "## Transcrição do Áudio\n",
    "Utilizamos o modelo Whisper para transcrever o áudio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b109794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GitHub Projects\\tcc-ata-ia\\venv\\lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcrição concluída:\n",
      " A Universidade Federal de Sejip aprovou recentemente a criação do curso de graduação em inteligência artificial. Quem vai falar sobre o assunto a partir de agora com a gente aqui na UFIS FM é o professor Hendrik Macedo do Departamento de Computação da UFIS. Na satisfação ouvir o professor aqui na UFIS FM como surgiu a proposta de criação desse curso de bacharelado em IA. Boa tarde. Boa tarde, Josaphá. Eu e o que agradeço a oportunidade de esclarecer esse assunto. Veja bem, nós temos associados \n"
     ]
    }
   ],
   "source": [
    "# Carregar o modelo Whisper\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "model = whisper.load_model(\"small\", device=device)\n",
    "\n",
    "# Transcrever o áudio\n",
    "result = model.transcribe(str(audio_path))\n",
    "transcription = result[\"text\"]\n",
    "\n",
    "print(\"Transcrição concluída:\")\n",
    "print(transcription[:500])  # Exibir os primeiros 500 caracteres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203f07b2",
   "metadata": {},
   "source": [
    "## Nomeação de Entidades (NER)\n",
    "Identificamos entidades nomeadas na transcrição utilizando um modelo pré-treinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1977f229",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GitHub Projects\\tcc-ata-ia\\venv\\lib\\site-packages\\transformers\\pipelines\\token_classification.py:170: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"simple\"` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Carregar o pipeline de NER\n",
    "ner_pipeline = pipeline(\"ner\", model=\"lfcc/bert-portuguese-ner\", grouped_entities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1f22bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entidades identificadas:\n",
      "{'entity_group': 'Organizacao', 'score': 0.8274329, 'word': 'Universidade Federal de Sejip', 'start': 2, 'end': 31}\n",
      "{'entity_group': 'Organizacao', 'score': 0.5980847, 'word': 'UF', 'start': 182, 'end': 184}\n",
      "{'entity_group': 'Organizacao', 'score': 0.4919821, 'word': '##IS', 'start': 184, 'end': 186}\n",
      "{'entity_group': 'Pessoa', 'score': 0.9830049, 'word': 'Hend', 'start': 204, 'end': 208}\n",
      "{'entity_group': 'Pessoa', 'score': 0.9813471, 'word': '##ri', 'start': 208, 'end': 210}\n",
      "{'entity_group': 'Pessoa', 'score': 0.96631706, 'word': '##k Macedo', 'start': 210, 'end': 218}\n",
      "{'entity_group': 'Organizacao', 'score': 0.50499254, 'word': 'UF', 'start': 252, 'end': 254}\n",
      "{'entity_group': 'Organizacao', 'score': 0.5281395, 'word': '##IS', 'start': 254, 'end': 256}\n",
      "{'entity_group': 'Organizacao', 'score': 0.6223447, 'word': 'UF', 'start': 298, 'end': 300}\n",
      "{'entity_group': 'Organizacao', 'score': 0.54624575, 'word': '##IS', 'start': 300, 'end': 302}\n",
      "{'entity_group': 'Pessoa', 'score': 0.9642536, 'word': 'Jos', 'start': 396, 'end': 399}\n",
      "{'entity_group': 'Pessoa', 'score': 0.96730196, 'word': '##ap', 'start': 399, 'end': 401}\n",
      "{'entity_group': 'Pessoa', 'score': 0.9372727, 'word': '##há', 'start': 401, 'end': 403}\n",
      "{'entity_group': 'Data', 'score': 0.5815711, 'word': '##1', 'start': 270, 'end': 271}\n",
      "{'entity_group': 'Data', 'score': 0.5335257, 'word': '202', 'start': 578, 'end': 581}\n",
      "{'entity_group': 'Data', 'score': 0.82265675, 'word': '##3', 'start': 581, 'end': 582}\n",
      "{'entity_group': 'Data', 'score': 0.81304955, 'word': '##4', 'start': 889, 'end': 890}\n",
      "{'entity_group': 'Organizacao', 'score': 0.76887447, 'word': 'Federal de Goiás', 'start': 1282, 'end': 1298}\n",
      "{'entity_group': 'Data', 'score': 0.6316687, 'word': '##5', 'start': 1478, 'end': 1479}\n",
      "{'entity_group': 'Organizacao', 'score': 0.365898, 'word': '##IS', 'start': 2019, 'end': 2021}\n",
      "{'entity_group': 'Organizacao', 'score': 0.87348783, 'word': 'Universidade Federal de Saúde', 'start': 1273, 'end': 1302}\n",
      "{'entity_group': 'Organizacao', 'score': 0.53071696, 'word': 'Blo', 'start': 391, 'end': 394}\n",
      "{'entity_group': 'Organizacao', 'score': 0.53367794, 'word': '##om', 'start': 394, 'end': 396}\n",
      "{'entity_group': 'Organizacao', 'score': 0.6052854, 'word': '##berg Intelligence', 'start': 396, 'end': 413}\n",
      "{'entity_group': 'Local', 'score': 0.4760959, 'word': 'Estados Unidos', 'start': 560, 'end': 574}\n",
      "{'entity_group': 'Data', 'score': 0.43611705, 'word': '202', 'start': 788, 'end': 791}\n",
      "{'entity_group': 'Data', 'score': 0.4066432, 'word': '##4', 'start': 791, 'end': 792}\n",
      "{'entity_group': 'Profissao', 'score': 0.55231583, 'word': 'engenheiro', 'start': 866, 'end': 876}\n",
      "{'entity_group': 'Profissao', 'score': 0.50071454, 'word': 'engenheiro', 'start': 887, 'end': 897}\n",
      "{'entity_group': 'Profissao', 'score': 0.4575386, 'word': 'cientista', 'start': 926, 'end': 935}\n",
      "{'entity_group': 'Data', 'score': 0.532204, 'word': '202', 'start': 409, 'end': 412}\n",
      "{'entity_group': 'Data', 'score': 0.4673788, 'word': '##5', 'start': 412, 'end': 413}\n",
      "{'entity_group': 'Organizacao', 'score': 0.46015248, 'word': '##IS', 'start': 576, 'end': 578}\n",
      "{'entity_group': 'Organizacao', 'score': 0.48375452, 'word': '##IS', 'start': 673, 'end': 675}\n",
      "{'entity_group': 'Local', 'score': 0.47180775, 'word': 'Brasil', 'start': 1195, 'end': 1201}\n",
      "{'entity_group': 'Organizacao', 'score': 0.50907975, 'word': 'UF', 'start': 1424, 'end': 1426}\n",
      "{'entity_group': 'Organizacao', 'score': 0.5145232, 'word': '##PE', 'start': 1426, 'end': 1428}\n",
      "{'entity_group': 'Organizacao', 'score': 0.46369398, 'word': 'UF', 'start': 1451, 'end': 1453}\n",
      "{'entity_group': 'Organizacao', 'score': 0.37510818, 'word': '##G', 'start': 1453, 'end': 1454}\n",
      "{'entity_group': 'Data', 'score': 0.47928402, 'word': '##6', 'start': 13, 'end': 14}\n",
      "{'entity_group': 'Pessoa', 'score': 0.9846549, 'word': 'R', 'start': 1742, 'end': 1743}\n",
      "{'entity_group': 'Pessoa', 'score': 0.9821087, 'word': '##ênd', 'start': 1743, 'end': 1746}\n",
      "{'entity_group': 'Pessoa', 'score': 0.96641564, 'word': '##ric Macedo', 'start': 1746, 'end': 1756}\n",
      "{'entity_group': 'Organizacao', 'score': 0.53230035, 'word': 'UF', 'start': 1801, 'end': 1803}\n",
      "{'entity_group': 'Organizacao', 'score': 0.5396359, 'word': '##IS', 'start': 1803, 'end': 1805}\n",
      "{'entity_group': 'Organizacao', 'score': 0.5994559, 'word': 'UF', 'start': 1838, 'end': 1840}\n",
      "{'entity_group': 'Organizacao', 'score': 0.55475235, 'word': '##IS', 'start': 1840, 'end': 1842}\n",
      "{'entity_group': 'Pessoa', 'score': 0.9818304, 'word': 'Jos', 'start': 1900, 'end': 1903}\n",
      "{'entity_group': 'Pessoa', 'score': 0.98199344, 'word': '##ap', 'start': 1903, 'end': 1905}\n",
      "{'entity_group': 'Pessoa', 'score': 0.969429, 'word': '##han', 'start': 1905, 'end': 1908}\n",
      "{'entity_group': 'Pessoa', 'score': 0.8504973, 'word': '##e To', 'start': 1908, 'end': 1912}\n",
      "{'entity_group': 'Organizacao', 'score': 0.54608923, 'word': '##IS', 'start': 1921, 'end': 1923}\n"
     ]
    }
   ],
   "source": [
    "# Função para dividir o texto em blocos menores\n",
    "def split_text(text, max_length=350):\n",
    "    words = text.split()\n",
    "    for i in range(0, len(words), max_length):\n",
    "        yield \" \".join(words[i:i + max_length])\n",
    "\n",
    "# Dividir a transcrição em blocos menores\n",
    "text_blocks = list(split_text(transcription, max_length=350))\n",
    "\n",
    "# Aplicar NER em cada bloco\n",
    "entities = []\n",
    "for block in text_blocks:\n",
    "    entities.extend(ner_pipeline(block))\n",
    "\n",
    "print(\"Entidades identificadas:\")\n",
    "for entity in entities:\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9866fbab",
   "metadata": {},
   "source": [
    "## Geração de Ata\n",
    "Com base na transcrição e nas entidades, geramos um resumo estruturado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9160531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumo gerado:\n",
      "[{'summary_text': \"'Não vão aprender a usar chat APT', diz professor da UFIS. A universidade quer que o curso de inteligência artificial seja um dos mais concorridos do Brasil. E a gente tem uma preocupação com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física,\"}]\n"
     ]
    }
   ],
   "source": [
    "# Carregar o modelo de sumarização\n",
    "# summarizer = pipeline(\"summarization\", model=\"pierreguillou/t5-base-pt-sum-cnndm-242M\")\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "model_name = \"recogna-nlp/ptt5-base-summ\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Gerar resumo\n",
    "summary = summarizer(transcription, max_length=500, min_length=50, do_sample=False)\n",
    "\n",
    "print(\"Resumo gerado:\")\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.8.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
