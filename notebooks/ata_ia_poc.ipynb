{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b60a5c99",
   "metadata": {},
   "source": [
    "# POC - Geração Automática de Atas de Reunião com IA\n",
    "\n",
    "Este notebook implementa uma prova de conceito para geração automática de atas de reunião usando:\n",
    "1. **Carregamento de áudio** - Suporte a arquivos .mp3, .wav, .m4a\n",
    "2. **Diarização** - Separação de speakers com pyannote.audio  \n",
    "3. **Transcrição** - Conversão de áudio para texto com Whisper\n",
    "4. **Geração de ata** - Processamento com OpenAI API para criar ata estruturada\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa76a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai-whisper in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (20250625)\n",
      "Requirement already satisfied: transformers in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (4.46.3)\n",
      "Requirement already satisfied: bert-extractive-summarizer in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: protobuf in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (5.29.5)\n",
      "Requirement already satisfied: sentencepiece in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: tqdm in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: more-itertools in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from openai-whisper) (10.5.0)\n",
      "Requirement already satisfied: numba in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from openai-whisper) (0.58.1)\n",
      "Requirement already satisfied: numpy in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from openai-whisper) (1.24.4)\n",
      "Requirement already satisfied: tiktoken in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from openai-whisper) (0.7.0)\n",
      "Requirement already satisfied: torch in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from openai-whisper) (2.4.1)\n",
      "Requirement already satisfied: filelock in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from transformers) (0.34.3)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: scikit-learn in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from bert-extractive-summarizer) (1.3.2)\n",
      "Requirement already satisfied: spacy in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from bert-extractive-summarizer) (3.7.5)\n",
      "Requirement already satisfied: colorama in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.13.2)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from numba->openai-whisper) (0.41.1)\n",
      "Requirement already satisfied: importlib-metadata in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from numba->openai-whisper) (8.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from requests->transformers) (2025.7.14)\n",
      "Requirement already satisfied: scipy>=1.5.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from scikit-learn->bert-extractive-summarizer) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from scikit-learn->bert-extractive-summarizer) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from scikit-learn->bert-extractive-summarizer) (3.5.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from spacy->bert-extractive-summarizer) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from spacy->bert-extractive-summarizer) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from spacy->bert-extractive-summarizer) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from spacy->bert-extractive-summarizer) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from spacy->bert-extractive-summarizer) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from spacy->bert-extractive-summarizer) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from spacy->bert-extractive-summarizer) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from spacy->bert-extractive-summarizer) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from spacy->bert-extractive-summarizer) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from spacy->bert-extractive-summarizer) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from spacy->bert-extractive-summarizer) (0.16.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from spacy->bert-extractive-summarizer) (2.10.6)\n",
      "Requirement already satisfied: jinja2 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from spacy->bert-extractive-summarizer) (3.1.6)\n",
      "Requirement already satisfied: setuptools in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from spacy->bert-extractive-summarizer) (56.0.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from spacy->bert-extractive-summarizer) (3.4.1)\n",
      "Requirement already satisfied: sympy in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from torch->openai-whisper) (1.13.3)\n",
      "Requirement already satisfied: networkx in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from torch->openai-whisper) (3.1)\n",
      "Requirement already satisfied: language-data>=1.2 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy->bert-extractive-summarizer) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->bert-extractive-summarizer) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->bert-extractive-summarizer) (2.27.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy->bert-extractive-summarizer) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy->bert-extractive-summarizer) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy->bert-extractive-summarizer) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy->bert-extractive-summarizer) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy->bert-extractive-summarizer) (14.1.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy->bert-extractive-summarizer) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy->bert-extractive-summarizer) (7.3.0.post1)\n",
      "Requirement already satisfied: zipp>=3.20 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from importlib-metadata->numba->openai-whisper) (3.20.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from jinja2->spacy->bert-extractive-summarizer) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->bert-extractive-summarizer) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->bert-extractive-summarizer) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->bert-extractive-summarizer) (2.19.2)\n",
      "Requirement already satisfied: wrapt in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->bert-extractive-summarizer) (1.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\github projects\\tcc-ata-ia\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->bert-extractive-summarizer) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "# Instalação das dependências necessárias\n",
    "!pip install git+https://github.com/openai/whisper.git -q\n",
    "!pip install openai -q\n",
    "!pip install pyannote.audio -q\n",
    "!pip install torch torchvision torchaudio -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683554f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GitHub Projects\\tcc-ata-ia\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuração inicial concluída.\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from pyannote.audio import Pipeline\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda74880",
   "metadata": {},
   "source": [
    "## Configuração dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688fa42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo carregado: ..\\data\\raw\\audio\\entrevista_ufs_fm.mp3\n"
     ]
    }
   ],
   "source": [
    "# Configurar a API da OpenAI\n",
    "# Substitua pela sua chave de API ou use variável de ambiente\n",
    "OPENAI_API_KEY = \"sua-chave-aqui\"  # ou os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Carregar modelo Whisper\n",
    "print(\"Carregando modelo Whisper...\")\n",
    "whisper_model = whisper.load_model(\"small\")  # Pode usar \"medium\" ou \"large\" para melhor qualidade\n",
    "print(\"Modelo Whisper carregado com sucesso!\")\n",
    "\n",
    "# Configurar pipeline de diarização\n",
    "print(\"Configurando pipeline de diarização...\")\n",
    "# Nota: Para usar pyannote, você precisa aceitar os termos em: https://huggingface.co/pyannote/speaker-diarization\n",
    "diarization_pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization@2.1\")\n",
    "print(\"Pipeline de diarização configurado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83da1979",
   "metadata": {},
   "source": [
    "## Funções Principais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b109794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GitHub Projects\\tcc-ata-ia\\venv\\lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcrição concluída:\n",
      " A Universidade Federal de Sejip aprovou recentemente a criação do curso de graduação em inteligência artificial. Quem vai falar sobre o assunto a partir de agora com a gente aqui na UFIS FM é o professor Hendrik Macedo do Departamento de Computação da UFIS. Na satisfação ouvir o professor aqui na UFIS FM como surgiu a proposta de criação desse curso de bacharelado em IA. Boa tarde. Boa tarde, Josaphá. Eu e o que agradeço a oportunidade de esclarecer esse assunto. Veja bem, nós temos associados \n"
     ]
    }
   ],
   "source": [
    "def transcribe_audio(audio_path):\n",
    "    \"\"\"\n",
    "    Transcreve áudio usando Whisper\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Transcrevendo áudio: {audio_path}\")\n",
    "        result = whisper_model.transcribe(audio_path, language=\"pt\")\n",
    "        return result[\"text\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Erro na transcrição: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def perform_diarization(audio_path):\n",
    "    \"\"\"\n",
    "    Realiza diarização (separação de speakers) do áudio\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Realizando diarização: {audio_path}\")\n",
    "        diarization = diarization_pipeline(audio_path)\n",
    "        \n",
    "        # Converter resultado para formato mais legível\n",
    "        speakers_info = []\n",
    "        for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "            speakers_info.append({\n",
    "                \"speaker\": speaker,\n",
    "                \"start\": turn.start,\n",
    "                \"end\": turn.end,\n",
    "                \"duration\": turn.end - turn.start\n",
    "            })\n",
    "        \n",
    "        return speakers_info\n",
    "    except Exception as e:\n",
    "        print(f\"Erro na diarização: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203f07b2",
   "metadata": {},
   "source": [
    "## Geração de Ata com OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1977f229",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GitHub Projects\\tcc-ata-ia\\venv\\lib\\site-packages\\transformers\\pipelines\\token_classification.py:170: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"simple\"` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def generate_meeting_minutes(transcription, speakers_info=None):\n",
    "    \"\"\"\n",
    "    Gera ata de reunião usando OpenAI API\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Preparar informações de speakers se disponível\n",
    "        speaker_context = \"\"\n",
    "        if speakers_info:\n",
    "            unique_speakers = list(set([s[\"speaker\"] for s in speakers_info]))\n",
    "            speaker_context = f\"\\n\\nParticipantes identificados: {', '.join(unique_speakers)}\"\n",
    "        \n",
    "        system_prompt = \"\"\"Você é um assistente especializado em gerar atas de reunião. \n",
    "        Sua tarefa é analisar a transcrição fornecida e criar uma ata estruturada e professional.\n",
    "        \n",
    "        A ata deve conter:\n",
    "        1. Cabeçalho com data e participantes\n",
    "        2. Resumo executivo dos principais pontos\n",
    "        3. Tópicos discutidos organizados por assunto\n",
    "        4. Decisões tomadas e responsáveis\n",
    "        5. Próximos passos e prazos\n",
    "        6. Observações adicionais se necessário\n",
    "        \n",
    "        Mantenha um tom formal e objetivo. Organize as informações de forma clara e hierárquica.\"\"\"\n",
    "        \n",
    "        user_prompt = f\"\"\"Transcrição da reunião:\n",
    "        {transcription}\n",
    "        {speaker_context}\n",
    "        \n",
    "        Por favor, gere uma ata completa e bem estruturada baseada nesta transcrição.\"\"\"\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",  # ou \"gpt-3.5-turbo\" para economia\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0.3,  # Baixa criatividade para manter precisão\n",
    "            max_tokens=2000\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erro na geração da ata: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f22bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entidades identificadas:\n",
      "{'entity_group': 'Organizacao', 'score': 0.8274329, 'word': 'Universidade Federal de Sejip', 'start': 2, 'end': 31}\n",
      "{'entity_group': 'Organizacao', 'score': 0.5980847, 'word': 'UF', 'start': 182, 'end': 184}\n",
      "{'entity_group': 'Organizacao', 'score': 0.4919821, 'word': '##IS', 'start': 184, 'end': 186}\n",
      "{'entity_group': 'Pessoa', 'score': 0.9830049, 'word': 'Hend', 'start': 204, 'end': 208}\n",
      "{'entity_group': 'Pessoa', 'score': 0.9813471, 'word': '##ri', 'start': 208, 'end': 210}\n",
      "{'entity_group': 'Pessoa', 'score': 0.96631706, 'word': '##k Macedo', 'start': 210, 'end': 218}\n",
      "{'entity_group': 'Organizacao', 'score': 0.50499254, 'word': 'UF', 'start': 252, 'end': 254}\n",
      "{'entity_group': 'Organizacao', 'score': 0.5281395, 'word': '##IS', 'start': 254, 'end': 256}\n",
      "{'entity_group': 'Organizacao', 'score': 0.6223447, 'word': 'UF', 'start': 298, 'end': 300}\n",
      "{'entity_group': 'Organizacao', 'score': 0.54624575, 'word': '##IS', 'start': 300, 'end': 302}\n",
      "{'entity_group': 'Pessoa', 'score': 0.9642536, 'word': 'Jos', 'start': 396, 'end': 399}\n",
      "{'entity_group': 'Pessoa', 'score': 0.96730196, 'word': '##ap', 'start': 399, 'end': 401}\n",
      "{'entity_group': 'Pessoa', 'score': 0.9372727, 'word': '##há', 'start': 401, 'end': 403}\n",
      "{'entity_group': 'Data', 'score': 0.5815711, 'word': '##1', 'start': 270, 'end': 271}\n",
      "{'entity_group': 'Data', 'score': 0.5335257, 'word': '202', 'start': 578, 'end': 581}\n",
      "{'entity_group': 'Data', 'score': 0.82265675, 'word': '##3', 'start': 581, 'end': 582}\n",
      "{'entity_group': 'Data', 'score': 0.81304955, 'word': '##4', 'start': 889, 'end': 890}\n",
      "{'entity_group': 'Organizacao', 'score': 0.76887447, 'word': 'Federal de Goiás', 'start': 1282, 'end': 1298}\n",
      "{'entity_group': 'Data', 'score': 0.6316687, 'word': '##5', 'start': 1478, 'end': 1479}\n",
      "{'entity_group': 'Organizacao', 'score': 0.365898, 'word': '##IS', 'start': 2019, 'end': 2021}\n",
      "{'entity_group': 'Organizacao', 'score': 0.87348783, 'word': 'Universidade Federal de Saúde', 'start': 1273, 'end': 1302}\n",
      "{'entity_group': 'Organizacao', 'score': 0.53071696, 'word': 'Blo', 'start': 391, 'end': 394}\n",
      "{'entity_group': 'Organizacao', 'score': 0.53367794, 'word': '##om', 'start': 394, 'end': 396}\n",
      "{'entity_group': 'Organizacao', 'score': 0.6052854, 'word': '##berg Intelligence', 'start': 396, 'end': 413}\n",
      "{'entity_group': 'Local', 'score': 0.4760959, 'word': 'Estados Unidos', 'start': 560, 'end': 574}\n",
      "{'entity_group': 'Data', 'score': 0.43611705, 'word': '202', 'start': 788, 'end': 791}\n",
      "{'entity_group': 'Data', 'score': 0.4066432, 'word': '##4', 'start': 791, 'end': 792}\n",
      "{'entity_group': 'Profissao', 'score': 0.55231583, 'word': 'engenheiro', 'start': 866, 'end': 876}\n",
      "{'entity_group': 'Profissao', 'score': 0.50071454, 'word': 'engenheiro', 'start': 887, 'end': 897}\n",
      "{'entity_group': 'Profissao', 'score': 0.4575386, 'word': 'cientista', 'start': 926, 'end': 935}\n",
      "{'entity_group': 'Data', 'score': 0.532204, 'word': '202', 'start': 409, 'end': 412}\n",
      "{'entity_group': 'Data', 'score': 0.4673788, 'word': '##5', 'start': 412, 'end': 413}\n",
      "{'entity_group': 'Organizacao', 'score': 0.46015248, 'word': '##IS', 'start': 576, 'end': 578}\n",
      "{'entity_group': 'Organizacao', 'score': 0.48375452, 'word': '##IS', 'start': 673, 'end': 675}\n",
      "{'entity_group': 'Local', 'score': 0.47180775, 'word': 'Brasil', 'start': 1195, 'end': 1201}\n",
      "{'entity_group': 'Organizacao', 'score': 0.50907975, 'word': 'UF', 'start': 1424, 'end': 1426}\n",
      "{'entity_group': 'Organizacao', 'score': 0.5145232, 'word': '##PE', 'start': 1426, 'end': 1428}\n",
      "{'entity_group': 'Organizacao', 'score': 0.46369398, 'word': 'UF', 'start': 1451, 'end': 1453}\n",
      "{'entity_group': 'Organizacao', 'score': 0.37510818, 'word': '##G', 'start': 1453, 'end': 1454}\n",
      "{'entity_group': 'Data', 'score': 0.47928402, 'word': '##6', 'start': 13, 'end': 14}\n",
      "{'entity_group': 'Pessoa', 'score': 0.9846549, 'word': 'R', 'start': 1742, 'end': 1743}\n",
      "{'entity_group': 'Pessoa', 'score': 0.9821087, 'word': '##ênd', 'start': 1743, 'end': 1746}\n",
      "{'entity_group': 'Pessoa', 'score': 0.96641564, 'word': '##ric Macedo', 'start': 1746, 'end': 1756}\n",
      "{'entity_group': 'Organizacao', 'score': 0.53230035, 'word': 'UF', 'start': 1801, 'end': 1803}\n",
      "{'entity_group': 'Organizacao', 'score': 0.5396359, 'word': '##IS', 'start': 1803, 'end': 1805}\n",
      "{'entity_group': 'Organizacao', 'score': 0.5994559, 'word': 'UF', 'start': 1838, 'end': 1840}\n",
      "{'entity_group': 'Organizacao', 'score': 0.55475235, 'word': '##IS', 'start': 1840, 'end': 1842}\n",
      "{'entity_group': 'Pessoa', 'score': 0.9818304, 'word': 'Jos', 'start': 1900, 'end': 1903}\n",
      "{'entity_group': 'Pessoa', 'score': 0.98199344, 'word': '##ap', 'start': 1903, 'end': 1905}\n",
      "{'entity_group': 'Pessoa', 'score': 0.969429, 'word': '##han', 'start': 1905, 'end': 1908}\n",
      "{'entity_group': 'Pessoa', 'score': 0.8504973, 'word': '##e To', 'start': 1908, 'end': 1912}\n",
      "{'entity_group': 'Organizacao', 'score': 0.54608923, 'word': '##IS', 'start': 1921, 'end': 1923}\n"
     ]
    }
   ],
   "source": [
    "def process_meeting_audio(audio_path):\n",
    "    \"\"\"\n",
    "    Função principal que processa o áudio completo:\n",
    "    1. Carregamento do áudio\n",
    "    2. Diarização\n",
    "    3. Transcrição\n",
    "    4. Geração da ata\n",
    "    \"\"\"\n",
    "    print(f\"=== Processando reunião: {audio_path} ===\")\n",
    "    print(f\"Iniciado em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    # Verificar se arquivo existe\n",
    "    if not os.path.exists(audio_path):\n",
    "        print(f\"Erro: Arquivo não encontrado - {audio_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Etapa 1: Diarização\n",
    "    print(\"\\n1. Realizando diarização...\")\n",
    "    speakers_info = perform_diarization(audio_path)\n",
    "    print(f\"   Encontrados {len(set([s['speaker'] for s in speakers_info]))} speakers diferentes\")\n",
    "    \n",
    "    # Etapa 2: Transcrição\n",
    "    print(\"\\n2. Transcrevendo áudio...\")\n",
    "    transcription = transcribe_audio(audio_path)\n",
    "    print(f\"   Transcrição concluída: {len(transcription)} caracteres\")\n",
    "    \n",
    "    # Etapa 3: Geração da ata\n",
    "    print(\"\\n3. Gerando ata de reunião...\")\n",
    "    meeting_minutes = generate_meeting_minutes(transcription, speakers_info)\n",
    "    \n",
    "    # Resultados\n",
    "    results = {\n",
    "        \"audio_file\": audio_path,\n",
    "        \"processing_date\": datetime.now().isoformat(),\n",
    "        \"speakers_info\": speakers_info,\n",
    "        \"transcription\": transcription,\n",
    "        \"meeting_minutes\": meeting_minutes\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n=== Processamento concluído em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ===\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9866fbab",
   "metadata": {},
   "source": [
    "## Teste da POC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9160531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumo gerado:\n",
      "[{'summary_text': \"'Não vão aprender a usar chat APT', diz professor da UFIS. A universidade quer que o curso de inteligência artificial seja um dos mais concorridos do Brasil. E a gente tem uma preocupação com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física, com a estrutura física,\"}]\n"
     ]
    }
   ],
   "source": [
    "# Teste com um arquivo de áudio das reuniões CONEPE/CONSU\n",
    "# Ajuste o caminho conforme necessário\n",
    "audio_file = \"../data/raw/audio/conepe/2024-01-22_conepe_#52.wav\"\n",
    "\n",
    "# Verificar se arquivo existe antes de processar\n",
    "if os.path.exists(audio_file):\n",
    "    print(f\"Processando arquivo: {audio_file}\")\n",
    "    results = process_meeting_audio(audio_file)\n",
    "    \n",
    "    if results:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"RESULTADOS DA POC\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        print(f\"\\nArquivo processado: {results['audio_file']}\")\n",
    "        print(f\"Data de processamento: {results['processing_date']}\")\n",
    "        \n",
    "        print(f\"\\nSpeakers identificados: {len(set([s['speaker'] for s in results['speakers_info']]))}\")\n",
    "        for speaker in set([s['speaker'] for s in results['speakers_info']]):\n",
    "            total_time = sum([s['duration'] for s in results['speakers_info'] if s['speaker'] == speaker])\n",
    "            print(f\"  - {speaker}: {total_time:.1f}s\")\n",
    "        \n",
    "        print(f\"\\nTranscrição ({len(results['transcription'])} caracteres):\")\n",
    "        print(\"-\" * 50)\n",
    "        print(results['transcription'][:500] + \"...\" if len(results['transcription']) > 500 else results['transcription'])\n",
    "        \n",
    "        print(f\"\\nAta de Reunião:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(results['meeting_minutes'])\n",
    "        \n",
    "        # Salvar resultados\n",
    "        output_file = f\"../data/atas-geradas/ata_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "        os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "        \n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"\\nResultados salvos em: {output_file}\")\n",
    "        \n",
    "else:\n",
    "    print(f\"Arquivo não encontrado: {audio_file}\")\n",
    "    print(\"Arquivos disponíveis:\")\n",
    "    audio_dir = \"../data/raw/audio\"\n",
    "    if os.path.exists(audio_dir):\n",
    "        for root, dirs, files in os.walk(audio_dir):\n",
    "            for file in files:\n",
    "                if file.endswith(('.wav', '.mp3', '.m4a')):\n",
    "                    print(f\"  - {os.path.join(root, file)}\")\n",
    "    else:\n",
    "        print(\"Diretório de áudio não encontrado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012f819f",
   "metadata": {},
   "source": [
    "## Notas e Próximos Passos\n",
    "\n",
    "### Configurações Necessárias\n",
    "\n",
    "1. **Chave da API OpenAI**: Configure sua chave da API OpenAI na célula de configuração\n",
    "2. **Hugging Face Token**: Para usar pyannote.audio, você precisa:\n",
    "   - Criar conta no Hugging Face\n",
    "   - Aceitar os termos em: https://huggingface.co/pyannote/speaker-diarization\n",
    "   - Configurar token de acesso\n",
    "\n",
    "### Melhorias Possíveis\n",
    "\n",
    "1. **Interface Gradio**: Adicionar interface web para upload de arquivos\n",
    "2. **Modelos maiores**: Usar Whisper \"medium\" ou \"large\" para melhor qualidade\n",
    "3. **Pós-processamento**: Adicionar correção ortográfica e formatação\n",
    "4. **Templates**: Criar templates específicos para diferentes tipos de reunião\n",
    "5. **Exportação**: Gerar PDFs e documentos Word da ata\n",
    "\n",
    "### Custos Estimados\n",
    "\n",
    "- **OpenAI API**: ~$0.03-0.06 por minuto de áudio (dependendo do modelo)\n",
    "- **Processamento local**: Whisper e diarização rodam localmente (gratuito)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c043ac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função utilitária para listar e testar diferentes arquivos\n",
    "def list_available_audio_files():\n",
    "    \"\"\"Lista todos os arquivos de áudio disponíveis\"\"\"\n",
    "    audio_files = []\n",
    "    audio_dir = \"../data/raw/audio\"\n",
    "    \n",
    "    if os.path.exists(audio_dir):\n",
    "        for root, dirs, files in os.walk(audio_dir):\n",
    "            for file in files:\n",
    "                if file.endswith(('.wav', '.mp3', '.m4a')):\n",
    "                    full_path = os.path.join(root, file)\n",
    "                    rel_path = os.path.relpath(full_path, \"..\")\n",
    "                    audio_files.append(rel_path)\n",
    "    \n",
    "    return sorted(audio_files)\n",
    "\n",
    "def quick_test(audio_file_path):\n",
    "    \"\"\"Teste rápido com apenas transcrição (sem diarização para economizar tempo)\"\"\"\n",
    "    print(f\"Teste rápido: {audio_file_path}\")\n",
    "    \n",
    "    if not os.path.exists(audio_file_path):\n",
    "        print(f\"Arquivo não encontrado: {audio_file_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Apenas transcrição\n",
    "    transcription = transcribe_audio(audio_file_path)\n",
    "    \n",
    "    # Gerar ata sem informação de speakers\n",
    "    meeting_minutes = generate_meeting_minutes(transcription)\n",
    "    \n",
    "    print(f\"\\nTranscrição ({len(transcription)} chars):\")\n",
    "    print(transcription[:300] + \"...\" if len(transcription) > 300 else transcription)\n",
    "    \n",
    "    print(f\"\\nAta gerada:\")\n",
    "    print(meeting_minutes)\n",
    "    \n",
    "    return {\"transcription\": transcription, \"meeting_minutes\": meeting_minutes}\n",
    "\n",
    "# Listar arquivos disponíveis\n",
    "print(\"Arquivos de áudio disponíveis:\")\n",
    "available_files = list_available_audio_files()\n",
    "for i, file in enumerate(available_files):\n",
    "    print(f\"{i+1:2d}. {file}\")\n",
    "\n",
    "# Exemplo de uso do teste rápido (descomente para usar)\n",
    "# if available_files:\n",
    "#     quick_test(available_files[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.8.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
